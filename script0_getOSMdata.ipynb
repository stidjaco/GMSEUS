{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab OpenStreetMap Data for Solar Panels and Arrays\n",
    "* Not all panel objects have an array associated with them, and vise versa in this dataset. \n",
    "* We process them here prior to combining with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#from shapely.geometry import MultiPolygon, Polygon, MultiPoint\n",
    "import re\n",
    "\n",
    "# Load config file\n",
    "def load_config(filename):\n",
    "    config = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # Strip whitespace and split by '='\n",
    "            key, value = line.strip().split('=')\n",
    "            # Try to convert to numeric values if possible\n",
    "            try:\n",
    "                value = float(value) if '.' in value else int(value)\n",
    "            except ValueError:\n",
    "                pass  # Leave as string if not a number\n",
    "            config[key] = value\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "wd = r'S:\\Users\\stidjaco\\R_files\\BigPanel'\n",
    "downloaded_path = os.path.join(wd, r'Data\\Downloaded')\n",
    "osmDownloadPath = os.path.join(downloaded_path, r'SolarDB\\OSM')\n",
    "osmPanelsPath = os.path.join(osmDownloadPath, r'Panels')\n",
    "osmArraysPath = os.path.join(osmDownloadPath, r'Arrays')\n",
    "uspvdb_path = os.path.join(downloaded_path, r'SolarDB\\USPVDB\\uspvdb_v2_0_20240801.shp')\n",
    "\n",
    "# Get US Boundary to subset global/non-CONUS datasets\n",
    "uspvdb = gpd.read_file(uspvdb_path) # USPVDB shapefile\n",
    "\n",
    "# Load the config from the text file\n",
    "config = load_config('config.txt')\n",
    "\n",
    "# Set variables to restrict OSM download to ground-mounted solar arrays and panel-rows\n",
    "minPanelRowArea = config['minPanelRowArea'] # 15 m2, minimum area for a single panel row from the 1st percentile panel area from Stid et al., 2022\n",
    "maxPanelRowArea = config['maxPanelRowArea'] # 254 m2 95th perccentile for a single panel row from Stid et al., 2022. MSU Solar Carport has max 1890m2\n",
    "minNumPanelRows = config['minNumPanelRows'] # 3 panels, minimum number of panels rows to form a ground mounted solar array, definition from Stid et al., 2022\n",
    "minPmArRatio = config['minPmArRatio'] # 18.8%, 20% was minimum ratio of panel perimeter to area ratio for panels from Stid et al., 2022, MSU Solar Carport has min 18.9%\n",
    "panelArrayBuff = config['panelArrayBuff'] # 10m buffer, 20m maximum distance between panel rows to form an array. We used 5m in Stid et al., 2022, but there are lower packing factors at greater latitudes (nativeID: '1229957948')\n",
    "arrayArrayBuff = config['arrayArrayBuff'] # 20m buffer, 40m maximum distance between arrays subsections of the same mount type to form a complete array. In Stid et al., 2022, we used 50m, but we checked for same installation year in addition to mount type.\n",
    "\n",
    "# Set limits for mount classification\n",
    "lengthRatioThresh = config['lengthRatioThresh']  # If length ratio < 3.0, set to dual_axis or else fixed_axis_diagonal, else single- or fixed-axis\n",
    "areaRatioThresh = config['areaRatioThresh']  # If area ratio < 0.15, set to fixed_diag_axis, else dual_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if folder exists, if not create it\n",
    "def checkFolder(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Function to assign mount type to solar panel-rows based on azimuth and panel geometry. Also returns all relevant design parameters for each panel-row. Requires the setting of a length ratio threshold and an area ratio threshold.\n",
    "def assignMountType(feature):\n",
    "    # Estimate azimuth of solar panel-row short edge\n",
    "    def getAzimuth(feature):\n",
    "        # Get the minimum bounding rectangle (oriented)\n",
    "        mbr = feature.geometry.minimum_rotated_rectangle\n",
    "        \n",
    "        # Get the coordinates of the MBR\n",
    "        coords = list(mbr.exterior.coords)\n",
    "        \n",
    "        # Calculate distances between consecutive vertices to determine lengths of edges\n",
    "        edge_lengths = []\n",
    "        for i in range(len(coords) - 1):  # last point is a duplicate of the first\n",
    "            p1, p2 = coords[i], coords[i + 1]\n",
    "            dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "            # Set a tempArea \n",
    "            # panels = panels**2 + (p2[1] - p1[1])**2)\n",
    "            edge_lengths.append(dist)\n",
    "        \n",
    "        # Identify shorter and longer sides\n",
    "        short_edge_index = np.argmin(edge_lengths[:2])  # first two edges are enough to find shorter side\n",
    "        \n",
    "        # Use the shorter edge for azimuth calculation\n",
    "        p1, p2 = coords[short_edge_index], coords[short_edge_index + 1]\n",
    "        \n",
    "        # Calculate the azimuth (angle relative to north, counterclockwise)\n",
    "        delta_x = p2[0] - p1[0]\n",
    "        delta_y = p2[1] - p1[1]\n",
    "\n",
    "        # Azimuth relative to north (y-axis)\n",
    "        angle_radians = np.arctan2(delta_x, delta_y)\n",
    "        angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "        # Normalize the angle to 0-360 degrees\n",
    "        if angle_degrees < 0:\n",
    "            angle_degrees += 360\n",
    "        if angle_degrees > 360:\n",
    "            angle_degrees -= 360\n",
    "        \n",
    "        # In the northern hemisphere, the a solar panel-row azimuth angle will never be towards the north (270 to 360 and 0 to 90 degrees). Therefore, if the azimuth is between 270 and 360 or 0 and 90, we need to add 180 degrees to the azimuth to get the correct orientation of the panel.\n",
    "        if 270 <= angle_degrees <= 360 or 0 <= angle_degrees <= 90:\n",
    "            angle_degrees += 180\n",
    "\n",
    "        return angle_degrees\n",
    "    \n",
    "    # Get the ratio of the long edge to the short edge of the panel (and the lengths of the short and long edges)\n",
    "    def getLengthRatio(feature):\n",
    "        # Get the minimum bounding rectangle (oriented)\n",
    "        mbr = feature.geometry.minimum_rotated_rectangle\n",
    "        \n",
    "        # Get the coordinates of the MBR\n",
    "        coords = list(mbr.exterior.coords)\n",
    "        \n",
    "        # Calculate distances between consecutive vertices\n",
    "        edge_lengths = []\n",
    "        for i in range(len(coords) - 1):  # last point is a duplicate of the first\n",
    "            p1, p2 = coords[i], coords[i + 1]\n",
    "            dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "            edge_lengths.append(dist)\n",
    "        \n",
    "        # Sort the edge lengths to identify short and long sides\n",
    "        sorted_lengths = sorted(edge_lengths[:2])  # Only need two sides (since rectangle has equal opposite sides)\n",
    "        short_edge = sorted_lengths[0]\n",
    "        long_edge = sorted_lengths[1]\n",
    "        \n",
    "        # Calculate the ratio of long edge to short edge\n",
    "        length_ratio = long_edge / short_edge\n",
    "        return length_ratio, short_edge, long_edge\n",
    "    \n",
    "    # Run the geteAzimuth function to get the azimuth of each panel row, getLengthRatio function to get the long and short edge ratio, and the and getAreaRatio function to get the panel area to bounding box ratio\n",
    "    azimuth = getAzimuth(feature)\n",
    "    length_ratio, short_edge, long_edge = getLengthRatio(feature)\n",
    "\n",
    "    # Assign mount type based on azimuth and area ratio \n",
    "    # Fixed-axis: If the azimuth is within 60 degrees of S, and length ratio is greater than 2.5\n",
    "    # Single-axis: If the azimuth is within 30 degrees of E or W (in southward radians), and length ratio is greater than 2.5\n",
    "    # Dual-axis: Any azimuth and the length ratio is less than 2.5\n",
    "    def classify_mount_type(azimuth, length_ratio):\n",
    "        # Check if azimuth is within 60 degrees to to S (180) -- Should never be north\n",
    "        if (abs(azimuth - 180) <= 60):\n",
    "            if length_ratio >= lengthRatioThresh:\n",
    "                return 'fixed_axis'\n",
    "        \n",
    "        # Check if azimuth is within 30 degrees of close to E (90) or W (270)\n",
    "        elif (abs(azimuth - 90) <= 30 or abs(azimuth - 270) <= 30):\n",
    "            if length_ratio >= lengthRatioThresh:\n",
    "                return 'single_axis'\n",
    "        \n",
    "        # Otherwise, classify as dual-axis\n",
    "        if length_ratio < lengthRatioThresh: # if area_ratio > areaRatioThresh and length_ratio < lengthRatioThresh:\n",
    "            return 'dual_axis'\n",
    "        \n",
    "        # Default case -- no panel-rows should be missed, but default to fixed-axis\n",
    "        return 'fixed_axis'\n",
    "    \n",
    "    # Classify the mount type\n",
    "    mount = classify_mount_type(azimuth, length_ratio)\n",
    "\n",
    "    # Assign mount type based on azimuth, and return the mount type, azimuth, length ratio, short edge, and long edge\n",
    "    return mount, azimuth, length_ratio, short_edge, long_edge\n",
    "\n",
    "# Function to check for and remove erroneous geometries in arrays\n",
    "def checkArrayGeometries(arrays): \n",
    "    # For a collection of reasons, array boundaries may contain erroneous geometries that result in a near-zero area, linestrings, or points. \n",
    "    # To check for and remove these, we'll explode arrays, calculate a temporary area, remove subarrays that are less than a minimum area, then dissolve by tempID.\n",
    "    arrays['tempDissolveID'] = (1 + np.arange(len(arrays)))  # Create a temporary ID for dissolving\n",
    "    arrays = arrays.explode(index_parts=False)\n",
    "    arrays['tempArea'] = arrays['geometry'].area\n",
    "    arrays = arrays[arrays['tempArea'] >= minPanelRowArea]\n",
    "    arrays = arrays.dissolve(by=['tempDissolveID'], as_index=False)\n",
    "    arrays = arrays.drop(columns=['tempArea', 'tempDissolveID'])\n",
    "    arrays = arrays.reset_index(drop=True)\n",
    "    return arrays\n",
    "\n",
    "# Function to create an array from a set of panel rows based on the distance between them\n",
    "def createArrayFromPanels(panels, buffDist, dissolveID, areaID='area'):\n",
    " \n",
    "    # Count panels per group before dissolving\n",
    "    panelCounts = panels.groupby(dissolveID).size().reset_index(name='numPanels')\n",
    "\n",
    "    # Get the total area of the panels within each group (sum of area column). \n",
    "    panelAreas = panels.groupby(dissolveID)[areaID].sum().reset_index(name='pnlArea')\n",
    "    \n",
    "    # Buffer the geometries by buffDist, dissovle boundaries, and unbuffer by buffDist* -1. Assign the number of objects being dissovle into a numPanels column.\n",
    "    arrays = panels.copy()\n",
    "    arrays['geometry'] = arrays.buffer(buffDist)\n",
    "    arrays = arrays.dissolve(by=[dissolveID], as_index=False)\n",
    "    arrays['geometry'] = arrays.buffer(buffDist * -1)\n",
    "\n",
    "    # Merge the panel counts and panel areas back into the dissolved array DataFrame. Select only the dissolveID and respective columns in the right df\n",
    "    arrays = arrays.merge(panelCounts[[dissolveID, 'numPanels']], on=dissolveID, how='left')\n",
    "    arrays = arrays.merge(panelAreas[[dissolveID, 'pnlArea']], on=dissolveID, how='left')\n",
    "\n",
    "    # Due to the buffering and unbuffering, some mulitpolygons contain erroneous geometries that result in a near-zero area, linestrings, or points. Remove these.\n",
    "    arrays = checkArrayGeometries(arrays)\n",
    "\n",
    "    # Reset index\n",
    "    arrays = arrays.reset_index(drop=True)\n",
    "    return arrays\n",
    "\n",
    "# Define a function that groups solar panels by mount type and proximity\n",
    "def groupArrayByMountAndProximity(gdf, buffer_distance):\n",
    "    # Set a temporary gdf to buffer\n",
    "    gdfBuffer = gdf.copy()\n",
    "\n",
    "    # Create a buffered version of the geometries\n",
    "    gdfBuffer['geometry'] = gdfBuffer.buffer(buffer_distance)\n",
    "\n",
    "    # Dissolve by mount\n",
    "    gdfBuffer = gdfBuffer.dissolve(by = 'mount')\n",
    "\n",
    "    # Explode the dissolved gdf\n",
    "    gdfBuffer = gdfBuffer.explode(index_parts=False).reset_index(drop = True)\n",
    "\n",
    "    # Assign a temp ID to the gdfBuffer\n",
    "    gdfBuffer['arrayID'] = range(0, len(gdfBuffer))\n",
    "\n",
    "    # Assign each panel the corresponding arrayID and total panel num in array by spatial join.\n",
    "    gdfOut = gpd.sjoin(gdf, gdfBuffer[['arrayID', 'geometry']], how='left', predicate='intersects').drop(columns='index_right')\n",
    "\n",
    "    # Group polygons into multiploygons by array ID. Keep the column\n",
    "    gdfOut = gdfOut.dissolve(by = 'arrayID').reset_index()\n",
    "\n",
    "    # Drop the arrayID column\n",
    "    gdfOut = gdfOut.drop(columns='arrayID', errors='ignore')\n",
    "    return gdfOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSM Get and Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that grabs all solar panel and array data from OSM for a given state\n",
    "def getSolarOSMData(state):\n",
    "\n",
    "    # Define your area of interest, As a test case, use Michigan\n",
    "    place = state + ', USA'\n",
    "\n",
    "    # Define custom tag for solar panels and arrays (NOTE: We will still have to filter out the arrays from panels)\n",
    "    panelsFilter = {'generator:source': 'solar'}\n",
    "    arraysFilter = {'plant:source': 'solar'}\n",
    "\n",
    "    # Retrieve the data from OSM\n",
    "    panelData = ox.features_from_place(place, panelsFilter)\n",
    "    arrayData = ox.features_from_place(place, arraysFilter)\n",
    " \n",
    "    # First, check if 'geometry' column exists and clean DataFrames by removing non-Polygon geometries\n",
    "    # Solves an issue where states like West Virgina, do not have arrayData\n",
    "    if 'geometry' in panelData.columns:\n",
    "        panelData = panelData[panelData['geometry'].apply(lambda x: x.geom_type in ['Polygon', 'MultiPolygon'])]\n",
    "    else:\n",
    "        panelData = gpd.GeoDataFrame(columns=['geometry'])  # Empty GeoDataFrame if no geometry column\n",
    "    if 'geometry' in arrayData.columns:\n",
    "        arrayData = arrayData[arrayData['geometry'].apply(lambda x: x.geom_type in ['Polygon', 'MultiPolygon'])]\n",
    "    else:\n",
    "        arrayData = gpd.GeoDataFrame(columns=['geometry'])  # Empty GeoDataFrame if no geometry column\n",
    "\n",
    "    ''' This code block tests for non-Polygon or MultiPolygon geometries in the dataframes.\n",
    "    # Create the same if else structure but for not 'Polygon' or 'MultiPolygon' geometries\n",
    "    # Solves an issue where states like West Virgina, do not have arrayData\n",
    "    if 'geometry' in panelData.columns:\n",
    "        panelData = panelData[panelData['geometry'].apply(lambda x: x.geom_type not in ['Polygon', 'MultiPolygon'])]\n",
    "    else:\n",
    "        panelData = gpd.GeoDataFrame(columns=['geometry'])\n",
    "    if 'geometry' in arrayData.columns:\n",
    "        arrayData = arrayData[arrayData['geometry'].apply(lambda x: x.geom_type not in ['Polygon', 'MultiPolygon'])]\n",
    "    else:\n",
    "        arrayData = gpd.GeoDataFrame(columns=['geometry'])\n",
    "    '''\n",
    "    \n",
    "    # Set CRS as WGS84 (OSM native proj). Then, transform the data to USPVDB CRS. Solves naive projection issues for emtpy array and panel\n",
    "    panelData = panelData.set_crs('EPSG:4326')\n",
    "    arrayData = arrayData.set_crs('EPSG:4326')\n",
    "    panelData = panelData.to_crs(uspvdb.crs)\n",
    "    arrayData = arrayData.to_crs(uspvdb.crs)\n",
    "\n",
    "    # Save the index as osmid\n",
    "    panelData['osmid'] = panelData.index\n",
    "    arrayData['osmid'] = arrayData.index\n",
    "\n",
    "    # Reset index\n",
    "    panelData = panelData.reset_index(drop=True)\n",
    "    arrayData = arrayData.reset_index(drop=True)\n",
    "\n",
    "    # Save osmid as string\n",
    "    panelData['osmid'] = panelData['osmid'].astype(str)\n",
    "    arrayData['osmid'] = arrayData['osmid'].astype(str)\n",
    "\n",
    "    # osmid column is currently structured as (way, 1155615180), we want only the number\n",
    "    panelData['osmid'] = panelData['osmid'].str.split(', ').str[1].str.replace(')', '')\n",
    "    arrayData['osmid'] = arrayData['osmid'].str.split(', ').str[1].str.replace(')', '')\n",
    "\n",
    "    # From panelData, remove all rows where 'location', 'building', or 'generator:place' column is = 'roof'. \n",
    "    # If these columns are not present, do nothing.\n",
    "    if 'location' in panelData.columns:\n",
    "        panelData = panelData[~panelData['location'].isin(['roof'])]\n",
    "    if 'building' in panelData.columns:\n",
    "        panelData = panelData[~panelData['building'].isin(['roof'])]\n",
    "    if 'generator:place' in panelData.columns:\n",
    "        panelData = panelData[~panelData['generator:place'].isin(['roof'])]\n",
    "\n",
    "    # Select the following columns for panelData: start_date, generator:method, osmid, source, name, geometry\n",
    "    # If any of these columns do not exist, create an empty column of NA values (as a string)\n",
    "    # Rename them to: instYr, modType, nativeID, Source, ProjName, geometry\n",
    "    # Ensure required columns exist, creating them with NA values if missing\n",
    "    # NOTE: there may be a 'generator:output:electricity' column, but we will ignore it for now and estiamte capacity from area and installation year later.\n",
    "    required_columns = {\n",
    "        'start_date': 'instYr',\n",
    "        'generator:method': 'modType',\n",
    "        'osmid': 'nativeID',\n",
    "        'source': 'Source',\n",
    "        'name': 'ProjName',\n",
    "        'geometry': 'geometry'}\n",
    "    for col, new_col in required_columns.items():\n",
    "        if col not in panelData.columns:\n",
    "            panelData[col] = pd.NA\n",
    "        panelData[new_col] = panelData[col]\n",
    "\n",
    "    # Select only the new columns\n",
    "    panelData = panelData[list(required_columns.values())]\n",
    "\n",
    "    # For arrayData, select the following columns: start_date, plant:method, osmid, source, name, plant:output:electricity, geometry\n",
    "    # If any of these columns do not exist, create an empty column of NA values (as a string)\n",
    "    # Rename them to: instYr, modType, nativeID, Source, ProjName, cap_mw, geometry\n",
    "    # Ensure required columns exist, creating them with NA values if missing\n",
    "    required_columns = {\n",
    "        'start_date': 'instYr',\n",
    "        'plant:method': 'modType',  \n",
    "        'osmid': 'nativeID',\n",
    "        'source': 'Source',\n",
    "        'name': 'ProjName',\n",
    "        'plant:output:electricity': 'cap_mw',\n",
    "        'geometry': 'geometry'}\n",
    "    for col, new_col in required_columns.items():\n",
    "        if col not in arrayData.columns:\n",
    "            arrayData[col] = pd.NA\n",
    "        arrayData[new_col] = arrayData[col]\n",
    "    \n",
    "    # Select only the new columns\n",
    "    arrayData = arrayData[list(required_columns.values())]\n",
    "\n",
    "    return panelData, arrayData\n",
    "\n",
    "# Define Function to Process Solar OSM Data\n",
    "def processSolarOSMData(state):    \n",
    "\n",
    "    # Get the solar panel and array data from OSM\n",
    "    panelData, arrayData = getSolarOSMData(state)\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~# \n",
    "    # Process Array Data # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # If arrayData is not empty, process arrayData\n",
    "    if not arrayData.empty:\n",
    "        # Capacity (cap_mw) is currently formated as a string and contains: '1 GW', '1 MW', '1 kW', or 'yes'. \n",
    "        # Formatting can also include '1GW', '1MW', '1kW', or the lower case version of any of these. \n",
    "        # It may also contain other strings that should be treated as nan, including existing nan values.\n",
    "        # If the string contains GW, remove everything except the number and multiply by 1000.\n",
    "        # If the string contais MW, remove everything except the number and leave as is.\n",
    "        # If the string contains kW, remove everything except the number and divide by 1000.\n",
    "        # If the string contains 'yes', set to -9999 (null value).\n",
    "        # If the string contains anything else, set to -9999 (null value).\n",
    "        # Function to process capacity\n",
    "        def process_capacity(value):\n",
    "            if pd.isna(value):\n",
    "                return np.nan\n",
    "            value = value.lower().strip()  # Make the string lowercase for easier matching and strip whitespaces\n",
    "            try:\n",
    "                if 'gw' in value:\n",
    "                    return float(value.replace('gw', '').strip()) * 1000\n",
    "                elif 'mw' in value:\n",
    "                    return float(value.replace('mw', '').strip())\n",
    "                elif 'kw' in value:\n",
    "                    return float(value.replace('kw', '').strip()) / 1000\n",
    "                elif value == 'yes':\n",
    "                    return -9999\n",
    "                else:\n",
    "                    return -9999\n",
    "            except ValueError:  # If the string cannot be converted to a float\n",
    "                return -9999\n",
    "\n",
    "        # Apply the function to the 'cap_mw' column dynamically. Round to 3 decimal places.\n",
    "        arrayData['cap_mw'] = arrayData['cap_mw'].apply(process_capacity).round(3)\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~ Get Panel Boundaries In Array Data (e.g. MSU Solar Carport, and 1229957948)\n",
    "\n",
    "        # Explode the MultiPolygons into individual Polygons\n",
    "        arrayData = arrayData.explode(index_parts=False).reset_index(drop=True)\n",
    "\n",
    "        # Filter out any rows where the geometry is invalid or empty\n",
    "        arrayData = arrayData[arrayData.geometry.notna()]\n",
    "\n",
    "        # Calculate the area of each array (in square meters)\n",
    "        arrayData['area'] = arrayData['geometry'].apply(lambda x: x.area if x.is_valid and x.area > 0 else np.nan)\n",
    "\n",
    "        # Calculate the perimeter-to-area ratio of each array\n",
    "        arrayData['PmArRatio'] = arrayData['geometry'].apply(lambda x: x.length / x.area if x.is_valid and x.area > 0 else np.nan)\n",
    "\n",
    "        # Drop rows where area or PmArRatio couldn't be calculated (NaN values)\n",
    "        arrayData = arrayData.dropna(subset=['area', 'PmArRatio'])\n",
    "\n",
    "        # IF: an array is less than minimum panel size, remove it (more likely to be rooftop or inverter station)\n",
    "        arrayData = arrayData[arrayData['area'] >= minPanelRowArea]\n",
    "\n",
    "        # IF: an array has a perimeter to area ratio greater than 0.188 or area is less than the max panel row area, save it to an panelArrayData dataframe. \n",
    "        # Then remove it from arrayData\n",
    "        panelInArrayData = arrayData[(arrayData['PmArRatio'] > minPmArRatio) | (arrayData['area'] < maxPanelRowArea)].reset_index(drop=True)\n",
    "        arrayData = arrayData[~arrayData['nativeID'].isin(panelInArrayData['nativeID'])]\n",
    "\n",
    "        # Dissolve by nativeID to return to multipolygon\n",
    "        arrayData = arrayData.dissolve(by = 'nativeID').reset_index()\n",
    "\n",
    "        # Remove panelArrayData shapes that are already in panelData, then merge the remaining dataframes\n",
    "        # First, check if data exists, then clean DataFrames by dropping rows with invalid or empty geometries, then remove overlapping arrays\n",
    "        if panelInArrayData is not None:\n",
    "            panelInArrayData = panelInArrayData[panelInArrayData.geometry.notna()]\n",
    "            if not panelInArrayData.empty:\n",
    "                panelInArrayData = panelInArrayData[~panelInArrayData.intersects(panelData.unary_union)]\n",
    "        panelData = pd.concat([panelData, panelInArrayData])\n",
    "    \n",
    "    # Else, if arrayData is empty, return an empty gdf for arrayData and panelInArrayData\n",
    "    else:\n",
    "        arrayData = gpd.GeoDataFrame(columns=['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'cap_mw', 'geometry'])\n",
    "        panelInArrayData = gpd.GeoDataFrame(columns=['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'geometry'])\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~# \n",
    "    # Process Panel Data # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # IF: panelData is not empty, process panelData\n",
    "    if not panelData.empty:\n",
    "        # Explode the MultiPolygons into individual Polygons\n",
    "        panelData = panelData.explode(index_parts=False).reset_index(drop=True)\n",
    "        panelData['nativeID'] = panelData['nativeID'] + '_' + panelData.groupby('nativeID').cumcount().astype(str)\n",
    "\n",
    "        # Filter out any rows where the geometry is invalid or empty\n",
    "        panelData = panelData[panelData.geometry.notna()]\n",
    "\n",
    "        # Calculate the area of each panel (in square meters)\n",
    "        panelData['area'] = panelData['geometry'].apply(lambda x: x.area if x.is_valid and x.area > 0 else np.nan)\n",
    "\n",
    "        # Calculate the perimeter-to-area ratio of each panel\n",
    "        panelData['PmArRatio'] = panelData['geometry'].apply(lambda x: x.length / x.area if x.is_valid and x.area > 0 else np.nan)\n",
    "\n",
    "        # Drop rows where area or PmArRatio couldn't be calculated (NaN values)\n",
    "        panelData = panelData.dropna(subset=['area', 'PmArRatio'])\n",
    "\n",
    "        # IF: a panel is less than the mimum panel row area, remove it (more likely to be rooftop or inverter station)\n",
    "        panelData = panelData[panelData['area'] >= minPanelRowArea]\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~ Get Array Boundaries In Panel Data\n",
    "\n",
    "        # IF: a panel has a perimeter to area ratio less than 0.188 or area is greater than max panel row area, save it to an arrayPanelData dataframe. \n",
    "        # Then remove it from panelData\n",
    "        arrayInPanelData = panelData[(panelData['PmArRatio'] < minPmArRatio) | (panelData['area'] > maxPanelRowArea)]\n",
    "        panelData = panelData[~panelData['nativeID'].isin(arrayInPanelData['nativeID'])]\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~ Get New Array Boudaries From Panel Data\n",
    "\n",
    "        # Get the mount type for each panel based on the geometry. assignMountType returns multiple columns, so only return the mount column.\n",
    "        panelData['mount'] = panelData.apply(assignMountType, axis=1).apply(lambda x: x[0]) # panelData['mount'] = panelData.apply(assignMountType, axis=1)\n",
    "\n",
    "        # Buffer the geometries by panelArrayBuff, dissovle boundaries by overlap, explode again, and unbuffer by panelArrayBuff * -1. \n",
    "        arrayFromPanelData = panelData.copy()\n",
    "        arrayFromPanelData['geometry'] = arrayFromPanelData.buffer(panelArrayBuff)\n",
    "        arrayFromPanelData = arrayFromPanelData.dissolve().explode(index_parts=False).reset_index(drop=True)\n",
    "\n",
    "        # Unbuffer the geometries by the same distance (negative buffer)\n",
    "        arrayFromPanelData['geometry'] = arrayFromPanelData.buffer(panelArrayBuff * -1)\n",
    "\n",
    "        # Check for and remove erroneous geometries in arrays\n",
    "        arrayFromPanelData = checkArrayGeometries(arrayFromPanelData)\n",
    "\n",
    "        # Save the most common mount type for each array based on panels that intersect with the array\n",
    "        arrayFromPanelData['mount'] = arrayFromPanelData['geometry'].apply(lambda x: panelData[panelData.intersects(x)]['mount'].mode()[0])\n",
    "\n",
    "        # IF any arrayFromPanelData shape is within a 10m buffer (arrayArrayBuff) of another arrayFromPanelData, merge them into a single array shape\n",
    "        arrayFromPanelData = groupArrayByMountAndProximity(arrayFromPanelData, arrayArrayBuff)\n",
    "\n",
    "        # Assign each array a unique identifier\n",
    "        arrayFromPanelData['arrayID'] = arrayFromPanelData.index\n",
    "\n",
    "        # Save the number of panels in each array based number of intersecting panels\n",
    "        arrayFromPanelData['PnlNum'] = arrayFromPanelData['geometry'].apply(lambda x: len(panelData[panelData.intersects(x)]))\n",
    "\n",
    "        # Assign each panel the corresponding arrayID and total panel num in array by spatial join.\n",
    "        panelData = gpd.sjoin(panelData, arrayFromPanelData[['arrayID', 'PnlNum', 'geometry']], how='left', predicate='intersects').drop(columns='index_right')\n",
    "\n",
    "        # Remove arrays and panels that do not meet the minimum number of panels in an array\n",
    "        arrayFromPanelData = arrayFromPanelData[arrayFromPanelData['PnlNum'] >= minNumPanelRows]\n",
    "        panelData = panelData[panelData['PnlNum'] >= minNumPanelRows]\n",
    "    \n",
    "    # Else, if panelData is empty, return an empty gdf for panelData, arrayInPanelData, and arrayFromPanelData\n",
    "    else:\n",
    "        panelData = gpd.GeoDataFrame(columns=['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'geometry', 'mount'])\n",
    "        arrayInPanelData = gpd.GeoDataFrame(columns=['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'geometry'])\n",
    "        arrayFromPanelData = gpd.GeoDataFrame(columns=['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'geometry', 'mount', 'arrayID', 'PnlNum'])\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~# \n",
    "    # Merge Array Data # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "    # Remove arrays with overlap in the following level of priority: arrayData, arrayInPanelData, arrayFromPanelData\n",
    "    # This order maintains arrays composed of subarray sections (multipolygons)\n",
    "    # First, check if data exists, then clean DataFrames by dropping rows with invalid or empty geometries, then remove overlapping arrays\n",
    "    # Solves an issue where an array df is empty, or contains errant geometries\n",
    "    if arrayInPanelData is not None:\n",
    "        arrayInPanelData = arrayInPanelData[arrayInPanelData.geometry.notna()]\n",
    "        if not arrayInPanelData.empty and not arrayData.empty:\n",
    "            arrayInPanelData = arrayInPanelData[~arrayInPanelData.intersects(arrayData.unary_union)]\n",
    "    if arrayFromPanelData is not None:\n",
    "        arrayFromPanelData = arrayFromPanelData[arrayFromPanelData.geometry.notna()]\n",
    "        if not arrayFromPanelData.empty and not arrayData.empty:\n",
    "            arrayFromPanelData = arrayFromPanelData[~arrayFromPanelData.intersects(arrayData.unary_union)]\n",
    "        if arrayInPanelData is not None and not arrayInPanelData.empty:\n",
    "            arrayFromPanelData = arrayFromPanelData[~arrayFromPanelData.intersects(arrayInPanelData.unary_union)]\n",
    "\n",
    "    # For arrayFromPanelData and arrayInPanelData, select the following columns: instYr, modType, nativeID, Source, ProjName, PnlNum, geometry\n",
    "    arrayFromPanelData = arrayFromPanelData[['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'geometry']]\n",
    "    arrayInPanelData = arrayInPanelData[['instYr', 'modType', 'nativeID', 'Source', 'ProjName', 'geometry']]\n",
    "\n",
    "    # For arrayFromPanelData and arrayInPanelData, add a cap_mw column and set it to -9999\n",
    "    arrayFromPanelData['cap_mw'] = -9999\n",
    "    arrayInPanelData['cap_mw'] = -9999\n",
    "\n",
    "    # Merge the array data\n",
    "    arrayData = pd.concat([arrayData, arrayInPanelData, arrayFromPanelData])\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "    # Fill Gaps and Save Data # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    # Save the final number of panels in each array based number of intersecting panels (overwrites initial count)\n",
    "    arrayData['PnlNum'] = arrayData['geometry'].apply(lambda x: len(panelData[panelData.intersects(x)]))\n",
    "\n",
    "    # For each array and each panel, calculate the area and save as a new column\n",
    "    panelData['area'] = panelData.area\n",
    "    arrayData['area'] = arrayData.area\n",
    "\n",
    "    # instYr values are formatted in several ways: 'YYYY-MM' or 'YYYY-MM-DD', 'MM/YYYY', 'YYYY', m/d/YYYY, with additional examples of: 'October 2018', 'March 1, 2015', '6/11/2011', '11/2019', '20183', '2021.0'\n",
    "    # We want to extract the year from these strings. If the year is not present, or if the year is not between 1900 and 2025, set to -9999\n",
    "    # Set the instYr column to an integer type when finished.\n",
    "    # Function to extract a valid year from various formats\n",
    "    def extract_year(instYr):\n",
    "        # Patterns to capture the year from different formats\n",
    "        patterns = [\n",
    "            r'(\\b\\d{4})[-/]\\d{2}[-/]\\d{2}',    # Match 'YYYY-MM-DD' or 'YYYY/MM/DD' (e.g., '2020-05-25')\n",
    "            r'(\\b\\d{4})[-/]\\d{2}',              # Match 'YYYY-MM' or 'YYYY/MM' (e.g., '2020-05')\n",
    "            r'\\b(\\d{1,2})/\\d{1,2}/(\\d{4})\\b',   # Match 'm/d/YYYY' or 'MM/DD/YYYY' (e.g., '6/11/2011')\n",
    "            r'([A-Za-z]+\\s+\\d{1,2},?\\s+)?(\\d{4})',  # Match 'Month YYYY' (e.g., 'October 2018') or 'March 1, 2015'\n",
    "            r'(\\b\\d{4}\\b)'                      # Match standalone 'YYYY' (e.g., '2020')\n",
    "        ]\n",
    "        \n",
    "        # Iterate through the patterns and try to match\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, str(instYr))\n",
    "            if match:\n",
    "                # Extract the year from the matched group\n",
    "                year = int(match.group(1)) if len(match.groups()) == 1 else int(match.group(2))\n",
    "                # Ensure the year is valid (between 1983 and 2025) -- 1983 is the install year of Solar One, the first commercial solar power plant in the US\n",
    "                if 1983 <= year <= 2025:\n",
    "                    return year\n",
    "        # If no valid year is found, return -9999\n",
    "        return -9999\n",
    "\n",
    "    # Apply the function to the 'instYr' column for both panelData and arrayData\n",
    "    panelData['instYr'] = panelData['instYr'].apply(extract_year).astype(int)\n",
    "    arrayData['instYr'] = arrayData['instYr'].apply(extract_year).astype(int)\n",
    "        \n",
    "    # For both dataframes, fill missing Source and ProjName with 'Unknown'\n",
    "    panelData['Source'] = panelData['Source'].fillna('Unknown')\n",
    "    arrayData['Source'] = arrayData['Source'].fillna('Unknown')\n",
    "    panelData['ProjName'] = panelData['ProjName'].fillna('Unknown')\n",
    "    arrayData['ProjName'] = arrayData['ProjName'].fillna('Unknown')\n",
    "\n",
    "    # For respective modType columns, replace 'photovoltaic' with 'c-Si' and 'thermal' with 'csp'. \n",
    "    panelData['modType'] = panelData['modType'].replace('photovoltaic', 'c-si')\n",
    "    arrayData['modType'] = arrayData['modType'].replace('photovoltaic', 'c-si')\n",
    "    panelData['modType'] = panelData['modType'].replace('thermal', 'csp')\n",
    "    arrayData['modType'] = arrayData['modType'].replace('thermal', 'csp')\n",
    "\n",
    "    # For both dataframes, fill missing modType with 'c-Si'\n",
    "    panelData['modType'] = panelData['modType'].fillna('c-si')\n",
    "    arrayData['modType'] = arrayData['modType'].fillna('c-si')\n",
    "\n",
    "    # Save the data to a shapefile in the OSM download folder for the state\n",
    "    panelData.to_file(os.path.join(osmPanelsPath, state + 'SolarPanels.shp'))\n",
    "    arrayData.to_file(os.path.join(osmArraysPath, state + 'SolarArrays.shp'))\n",
    "\n",
    "    # If desired, return the dataframes\n",
    "    #return panelData, arrayData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Function for Each CONUS State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 60 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 60 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 122 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 122 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arizona data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 59 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 59 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arkansas data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 222 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 222 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "California data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 108 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 108 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorado data has been downloaded and processed.\n",
      "Connecticut data has been downloaded and processed.\n",
      "Delaware data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 141 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 141 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florida data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 68 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 68 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Georgia data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 111 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 111 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idaho data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 69 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 69 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Illinois data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 42 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 42 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indiana data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 63 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 63 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iowa data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 86 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 86 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kansas data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 50 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 50 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kentucky data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 70 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 70 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louisiana data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 43 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 43 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maine data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 21 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 21 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maryland data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 15 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 15 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massachusetts data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 125 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 125 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michigan data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 122 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 122 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minnesota data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 58 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 58 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mississippi data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 87 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 87 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missouri data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 167 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 167 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\geopandas\\io\\file.py:610: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montana data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 85 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 85 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nebraska data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 116 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 116 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nevada data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 11 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 11 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Hampshire data has been downloaded and processed.\n",
      "New Jersey data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 132 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 132 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Mexico data has been downloaded and processed.\n",
      "New York data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 70 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 70 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Carolina data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 74 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 74 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Dakota data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 50 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 50 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ohio data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 88 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 88 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oklahoma data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 114 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 114 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oregon data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 53 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 53 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pennsylvania data has been downloaded and processed.\n",
      "Rhode Island data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 36 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 36 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Carolina data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 86 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 86 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Dakota data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 48 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 48 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tennessee data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 383 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 383 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texas data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 91 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 91 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utah data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 12 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 12 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vermont data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 58 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 58 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia data has been downloaded and processed.\n",
      "Washington data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 37 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 37 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\features.py:1053: FutureWarning: <class 'geopandas.array.GeometryArray'>._reduce will require a `keepdims` parameter in the future\n",
      "  gdf = gdf.dropna(axis=\"columns\", how=\"all\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West Virginia data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 82 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 82 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wisconsin data has been downloaded and processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 102 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n",
      "f:\\Python_Envs\\BigPanel\\Lib\\site-packages\\osmnx\\_overpass.py:254: UserWarning: This area is 102 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyoming data has been downloaded and processed.\n"
     ]
    }
   ],
   "source": [
    "# First, check if the OSM download folder exists, if not create it\n",
    "checkFolder(osmPanelsPath)\n",
    "checkFolder(osmArraysPath)\n",
    "\n",
    "# Get a list of all 48 states in the contiguous US )\n",
    "states = ['Alabama', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "\n",
    "# Loop through each state and get the solar data\n",
    "for state in states:\n",
    "    processSolarOSMData(state)\n",
    "    print(state + ' data has been downloaded and processed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile State Data into a National OSM Solar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stidjaco\\AppData\\Local\\Temp\\ipykernel_22940\\2460503533.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True)).to_crs(target_crs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of solar panels: 872972\n",
      "Total number of solar arrays: 10531\n",
      "Total area of solar panels: 116.41 km^2\n",
      "Total area of solar arrays: 2438.02 km^2\n"
     ]
    }
   ],
   "source": [
    "# Function to load geodataframes from all files in a folder\n",
    "def load_gdf(path, extension, target_crs):\n",
    "    files = [f for f in os.listdir(path) if f.endswith(f'.{extension}')]\n",
    "    dfs = [gpd.read_file(os.path.join(path, file)) for file in files]\n",
    "    # Directly concatenate and reproject\n",
    "    return gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True)).to_crs(target_crs)\n",
    "\n",
    "# Load all solar panel and array data\n",
    "panels = load_gdf(osmPanelsPath, 'shp', uspvdb.crs)\n",
    "arrays = load_gdf(osmArraysPath, 'shp', uspvdb.crs)\n",
    "\n",
    "# Print the number of solar panels and arrays\n",
    "print(f'Total number of solar panels: {len(panels)}')\n",
    "print(f'Total number of solar arrays: {len(arrays)}')\n",
    "\n",
    "# Print sum of area of arrays and panels in km\n",
    "print(f'Total area of solar panels: {panels.area.sum() / 1e6:.2f} km^2')\n",
    "print(f'Total area of solar arrays: {arrays.area.sum() / 1e6:.2f} km^2')\n",
    "\n",
    "# Save the data to a shapefile in the OSM download folder\n",
    "panels.to_file(os.path.join(osmDownloadPath, 'OSMSolarPanels.shp'))\n",
    "arrays.to_file(os.path.join(osmDownloadPath, 'OSMSolarArrays.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigPanel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
