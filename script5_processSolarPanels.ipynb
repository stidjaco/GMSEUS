{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Solar Panel Dataset from New Panel Delineation\n",
    "\n",
    "* Calls all panel shapes existing within all existing and digitized array boundaries (bound by NAIP availability)\n",
    "* Checks for panel delination quality and resulting array shape quality, removes low quality panel delineations based on perimeter to area ratio\n",
    "    * USPVDB and CCVPV have both been manually validated for correctness in their original creation\n",
    "    * Saves arrays (excluding USPVDB and CCVPV) where panels are not present OR panel delination was low quality, and exports as shape file to assess for comissions\n",
    "* Removes arrays and panels manually validated as comissions from remote sensing datasets\n",
    "* Creates new array shapes by buffering and dissolving panel boundaries\n",
    "    * USPVDB and CCVPV are both high array quality. So keep those shapes in the array dataset, but improve all other array boundaries if the new shape is of high quality\n",
    "* Saves high-quality panels objects as new shape file\n",
    "* Saves highest-quality array objects as new shape file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os \n",
    "\n",
    "# Load config file\n",
    "def load_config(filename):\n",
    "    config = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # Strip whitespace and split by '='\n",
    "            key, value = line.strip().split('=')\n",
    "            # Try to convert to numeric values if possible\n",
    "            try:\n",
    "                value = float(value) if '.' in value else int(value)\n",
    "            except ValueError:\n",
    "                pass  # Leave as string if not a number\n",
    "            config[key] = value\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder paths\n",
    "wd = r'S:\\Users\\stidjaco\\R_files\\BigPanel'\n",
    "downloaded_path = os.path.join(wd, r'Data\\Downloaded')\n",
    "derived_path = os.path.join(wd, r'Data\\Derived')\n",
    "derivedTemp_path = os.path.join(derived_path, r'intermediateProducts')\n",
    "\n",
    "# Set getPanels from GEE output folder path for two different approaches\n",
    "getPanels_path = os.path.join(derivedTemp_path, r'getPanelsGEEOutput')\n",
    "\n",
    "# GM-SEUS output initial paths\n",
    "gmseusArraysInitPath = os.path.join(derivedTemp_path, r'initialGMSEUS_Arrays.shp')\n",
    "gmseusPanelsInitPath = os.path.join(derivedTemp_path, r'initialGMSEUS_Panels.shp')\n",
    "\n",
    "# Set GM-SEUS NAIP classified panels and arrays path\n",
    "gmseusNaipPanelsPath = os.path.join(derived_path, r'GMSEUS/GMSEUS_NAIP_Panels.shp')\n",
    "gmseusNaipArraysPath = os.path.join(derived_path, r'GMSEUS/GMSEUS_NAIP_Arrays.shp')\n",
    "\n",
    "# Set a GM-SEUS array path for acquiring installation year (exploded grouped arrays -- SAM) and panel path\n",
    "gmseusArraysInstYrPath = os.path.join(derivedTemp_path, r'GMSEUS_Arrays_instYr.shp')\n",
    "gmseusPanelsFinalPath = os.path.join(derivedTemp_path, r'GMSEUS_Panels_ExistingAndNAIP.shp')\n",
    "gmseusArraysFromPanelsPath = os.path.join(derivedTemp_path, r'GMSEUS_ArraysFromPanels.shp')\n",
    "\n",
    "# Call the GM-SEUS arrays init to get crs\n",
    "gmseusArraysInit = gpd.read_file(gmseusArraysInitPath)\n",
    "gmseusCrs = gmseusArraysInit.crs\n",
    "\n",
    "# Set paths to USPVDB and CCVPV (we check if GMSEUSgeorect arrays are from these datasets)\n",
    "uspvdb_path = os.path.join(derivedTemp_path, r'uspvdb_poly.shp')\n",
    "ccvpv_path = os.path.join(derivedTemp_path, r'ccvpv_poly.shp')\n",
    "\n",
    "# Load the config from the text file\n",
    "config = load_config('config.txt')\n",
    "\n",
    "# Set general variables\n",
    "gee_crs = 4326 # native projection of Google Earth Engine exports\n",
    "minPanelRowArea = config['minPanelRowArea'] # 15 m2, minimum area for a single panel row from the 1st percentile panel area from Stid et al., 2022\n",
    "maxPanelRowArea = config['maxPanelRowArea'] # 254 m2 95th perccentile for a single panel row from Stid et al., 2022. MSU Solar Carport has max 1890m2\n",
    "minNumPanelRows = config['minNumPanelRows'] # 3 panels, minimum number of panels rows to form a ground mounted solar array, definition from Stid et al., 2022\n",
    "minPmArRatio = config['minPmArRatio'] # 18.8%, 20% was minimum ratio of panel perimeter to area ratio for panels from Stid et al., 2022, MSU Solar Carport has min 18.9%\n",
    "panelArrayBuff = config['panelArrayBuff'] # 10m buffer, 20m maximum distance between panel rows to form an array. We used 5m in Stid et al., 2022, but there are lower packing factors at greater latitudes (nativeID: '1229957948')\n",
    "arrayArrayBuff = config['arrayArrayBuff'] # 20m buffer, 40m maximum distance between arrays subsections of the same mount type to form a complete array. In Stid et al., 2022, we used 50m, but we checked for same installation year in addition to mount type.\n",
    "\n",
    "# Set limits for mount classification\n",
    "lengthRatioThresh = config['lengthRatioThresh']  # If length ratio < 3.0, set to dual_axis or else fixed_axis_diagonal, else single- or fixed-axis\n",
    "areaRatioThresh = config['areaRatioThresh']  # If area ratio < 0.15, set to fixed_diag_axis, else dual_axis\n",
    "\n",
    "# Set the threshold for Z-scores (3 standard deviations is a common choice, adjust if needed) and unique mount proportion. \n",
    "z_threshold = 3 # 3 standard deviations\n",
    "uniqueMountThreshold = 0.1 # 10% of the panel mount types in the array\n",
    "\n",
    "# Remove new arrays where the new array area is less than 0.25 * gmseus array area and where new array PmArRatio is less than the 99th percentile of gmseus PmArRatio\n",
    "newAreaThreshold = 0.25 # 25% of the original gmseus array area\n",
    "gmseusPmArRatioThreshold = 0.99 # 99th percentile\n",
    "\n",
    "# For this script wwhere we filter panel-rows based on shared geometrical similarity, the arrayID column is subArrID, because we exlode all sub array geometries in script3\n",
    "arrayIDcol = 'subArrID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign mount type to solar panel-rows based on azimuth and panel geometry. Also returns all relevant design parameters for each panel-row. Requires the setting of a length ratio threshold and an area ratio threshold.\n",
    "def assignMountType(feature):\n",
    "    # Estimate azimuth of solar panel-row short edge\n",
    "    def getAzimuth(feature):\n",
    "        # Get the minimum bounding rectangle (oriented)\n",
    "        mbr = feature.geometry.minimum_rotated_rectangle\n",
    "        \n",
    "        # Get the coordinates of the MBR\n",
    "        coords = list(mbr.exterior.coords)\n",
    "        \n",
    "        # Calculate distances between consecutive vertices to determine lengths of edges\n",
    "        edge_lengths = []\n",
    "        for i in range(len(coords) - 1):  # last point is a duplicate of the first\n",
    "            p1, p2 = coords[i], coords[i + 1]\n",
    "            dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "            # Set a tempArea \n",
    "            # panels = panels**2 + (p2[1] - p1[1])**2)\n",
    "            edge_lengths.append(dist)\n",
    "        \n",
    "        # Identify shorter and longer sides\n",
    "        short_edge_index = np.argmin(edge_lengths[:2])  # first two edges are enough to find shorter side\n",
    "        \n",
    "        # Use the shorter edge for azimuth calculation\n",
    "        p1, p2 = coords[short_edge_index], coords[short_edge_index + 1]\n",
    "        \n",
    "        # Calculate the azimuth (angle relative to north, counterclockwise)\n",
    "        delta_x = p2[0] - p1[0]\n",
    "        delta_y = p2[1] - p1[1]\n",
    "\n",
    "        # Azimuth relative to north (y-axis)\n",
    "        angle_radians = np.arctan2(delta_x, delta_y)\n",
    "        angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "        # Normalize the angle to 0-360 degrees\n",
    "        if angle_degrees < 0:\n",
    "            angle_degrees += 360\n",
    "        if angle_degrees > 360:\n",
    "            angle_degrees -= 360\n",
    "        \n",
    "        # In the northern hemisphere, the a solar panel-row azimuth angle will never be towards the north (270 to 360 and 0 to 90 degrees). Therefore, if the azimuth is between 270 and 360 or 0 and 90, we need to add 180 degrees to the azimuth to get the correct orientation of the panel.\n",
    "        if 270 <= angle_degrees <= 360 or 0 <= angle_degrees <= 90:\n",
    "            angle_degrees += 180\n",
    "\n",
    "        return angle_degrees\n",
    "    \n",
    "    # Get the ratio of the long edge to the short edge of the panel (and the lengths of the short and long edges)\n",
    "    def getLengthRatio(feature):\n",
    "        # Get the minimum bounding rectangle (oriented)\n",
    "        mbr = feature.geometry.minimum_rotated_rectangle\n",
    "        \n",
    "        # Get the coordinates of the MBR\n",
    "        coords = list(mbr.exterior.coords)\n",
    "        \n",
    "        # Calculate distances between consecutive vertices\n",
    "        edge_lengths = []\n",
    "        for i in range(len(coords) - 1):  # last point is a duplicate of the first\n",
    "            p1, p2 = coords[i], coords[i + 1]\n",
    "            dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "            edge_lengths.append(dist)\n",
    "        \n",
    "        # Sort the edge lengths to identify short and long sides\n",
    "        sorted_lengths = sorted(edge_lengths[:2])  # Only need two sides (since rectangle has equal opposite sides)\n",
    "        short_edge = sorted_lengths[0]\n",
    "        long_edge = sorted_lengths[1]\n",
    "        \n",
    "        # Calculate the ratio of long edge to short edge\n",
    "        length_ratio = long_edge / short_edge\n",
    "        return length_ratio, short_edge, long_edge\n",
    "    \n",
    "    # Run the geteAzimuth function to get the azimuth of each panel row, getLengthRatio function to get the long and short edge ratio, and the and getAreaRatio function to get the panel area to bounding box ratio\n",
    "    azimuth = getAzimuth(feature)\n",
    "    length_ratio, short_edge, long_edge = getLengthRatio(feature)\n",
    "\n",
    "    # Assign mount type based on azimuth and area ratio \n",
    "    # Fixed-axis: If the azimuth is within 60 degrees of S, and length ratio is greater than 2.5\n",
    "    # Single-axis: If the azimuth is within 30 degrees of E or W (in southward radians), and length ratio is greater than 2.5\n",
    "    # Dual-axis: Any azimuth and the length ratio is less than 2.5\n",
    "    def classify_mount_type(azimuth, length_ratio):\n",
    "        # Check if azimuth is within 60 degrees to to S (180) -- Should never be north\n",
    "        if (abs(azimuth - 180) <= 60):\n",
    "            if length_ratio >= lengthRatioThresh:\n",
    "                return 'fixed_axis'\n",
    "        \n",
    "        # Check if azimuth is within 30 degrees of close to E (90) or W (270)\n",
    "        elif (abs(azimuth - 90) <= 30 or abs(azimuth - 270) <= 30):\n",
    "            if length_ratio >= lengthRatioThresh:\n",
    "                return 'single_axis'\n",
    "        \n",
    "        # Otherwise, classify as dual-axis\n",
    "        if length_ratio < lengthRatioThresh: # if area_ratio > areaRatioThresh and length_ratio < lengthRatioThresh:\n",
    "            return 'dual_axis'\n",
    "        \n",
    "        # Default case -- no panel-rows should be missed, but default to fixed-axis\n",
    "        return 'fixed_axis'\n",
    "    \n",
    "    # Classify the mount type\n",
    "    mount = classify_mount_type(azimuth, length_ratio)\n",
    "\n",
    "    # Assign mount type based on azimuth, and return the mount type, azimuth, length ratio, short edge, and long edge\n",
    "    return mount, azimuth, length_ratio, short_edge, long_edge\n",
    "\n",
    "# Function to check for and remove erroneous geometries in arrays\n",
    "def checkArrayGeometries(arrays): \n",
    "    # For a collection of reasons, array boundaries may contain erroneous geometries that result in a near-zero area, linestrings, or points. \n",
    "    # To check for and remove these, we'll explode arrays, calculate a temporary area, remove subarrays that are less than a minimum area, then dissolve by tempID.\n",
    "    arrays['tempDissolveID'] = (1 + np.arange(len(arrays)))  # Create a temporary ID for dissolving\n",
    "    arrays = arrays.explode(index_parts=False)\n",
    "    arrays['tempArea'] = arrays['geometry'].area\n",
    "    arrays = arrays[arrays['tempArea'] >= minPanelRowArea]\n",
    "    arrays = arrays.dissolve(by=['tempDissolveID'], as_index=False)\n",
    "    arrays = arrays.drop(columns=['tempArea', 'tempDissolveID'])\n",
    "    arrays = arrays.reset_index(drop=True)\n",
    "    return arrays\n",
    "\n",
    "# Function to create an array from a set of panel rows based on the distance between them\n",
    "def createArrayFromPanels(panels, buffDist, dissolveID):\n",
    "    # Count panels per group before dissolving\n",
    "    panelCounts = panels.groupby(dissolveID).size().reset_index(name='numPanels')\n",
    "\n",
    "    # Get the total area of the panels within each group (sum of area column)\n",
    "    panelAreas = panels.groupby(dissolveID)['area'].sum().reset_index(name='pnlArea')\n",
    "    \n",
    "    # Buffer the geometries by buffDist, dissovle boundaries, and unbuffer by buffDist* -1. Assign the number of objects being dissovle into a numPanels column.\n",
    "    arrays = panels.copy()\n",
    "    arrays['geometry'] = arrays.buffer(buffDist)\n",
    "    arrays = arrays.dissolve(by=[dissolveID], as_index=False)\n",
    "    arrays['geometry'] = arrays.buffer(buffDist * -1)\n",
    "\n",
    "    # Merge the panel counts and panel areas back into the dissolved array DataFrame. Select only the dissolveID and respective columns in the right df\n",
    "    arrays = arrays.merge(panelCounts[[dissolveID, 'numPanels']], on=dissolveID, how='left')\n",
    "    arrays = arrays.merge(panelAreas[[dissolveID, 'pnlArea']], on=dissolveID, how='left')\n",
    "\n",
    "    # Due to the buffering and unbuffering, some mulitpolygons contain erroneous geometries that result in a near-zero area, linestrings, or points. Remove these.\n",
    "    arrays = checkArrayGeometries(arrays)\n",
    "\n",
    "    # Reset index\n",
    "    arrays = arrays.reset_index(drop=True)\n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Panel Data from GEE Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of newly delineated panel-rows: 2390864\n",
      "Total area of solar panels on initial processing: 686.66 km2\n"
     ]
    }
   ],
   "source": [
    "# Function to read in the shapefiles/geojsons from folder and return a processed panel geodataframe\n",
    "def getPanels_method(path):\n",
    "\n",
    "    # Function to load geodataframes if different files are present in the folder\n",
    "    def load_gdf(path, extension, target_crs):\n",
    "        files = [f for f in os.listdir(os.path.join(path)) if f.endswith(f'.{extension}')]\n",
    "        dfs = [gpd.read_file(os.path.join(path, file)) for file in files]\n",
    "        # Directly concatenate, set crs, and reproject\n",
    "        return gpd.GeoDataFrame(pd.concat(dfs, ignore_index=True)).set_crs(gee_crs).to_crs(target_crs)\n",
    "    \n",
    "    # Handle both GeoJson and Shp files, both may be present depending on script4 output requirements (vertex limit of geojson)\n",
    "    # Check what file extensions are present in the folder (either/or geojson or shapefile). \n",
    "    # If both are present, load both and concatenate. If only one is present, load that one.\n",
    "    geoJsonFileNum = len([f for f in os.listdir(os.path.join(path)) if f.endswith('.geojson')])\n",
    "    shpFileNum = len([f for f in os.listdir(os.path.join(path)) if f.endswith('.shp')])\n",
    "    if geoJsonFileNum > 0 and shpFileNum > 0:\n",
    "        solarPanelsJSON = load_gdf(path, 'geojson', gmseusCrs)\n",
    "        solarPanelsSHP = load_gdf(path, 'shp', gmseusCrs)\n",
    "        solarPanels = pd.concat([solarPanelsJSON, solarPanelsSHP], ignore_index=True)\n",
    "        print('Both geojson and shapefile found in the folder. Concatenating both.')\n",
    "    elif geoJsonFileNum > 0:\n",
    "        solarPanels = load_gdf(path, 'geojson', gmseusCrs)\n",
    "    elif shpFileNum > 0:\n",
    "        solarPanels = load_gdf(path, 'shp', gmseusCrs)\n",
    "    else:\n",
    "        raise ValueError('No valid file extensions found in the folder. Please provide either a geojson or shapefile.')\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Explode arrays into panels, remove array with missing panels\n",
    "\n",
    "    # Remove rows where pnlsPres == \"No\"\n",
    "    solarPanels = solarPanels[solarPanels['pnlsPres'] != 'No']\n",
    "\n",
    "    # Remove rows where pnlNum is 1\n",
    "    solarPanels = solarPanels[solarPanels['pnlNum'] > 1]\n",
    "\n",
    "    # Explode the multipolygons\n",
    "    solarPanels = solarPanels.explode(index_parts=False)\n",
    "\n",
    "    # Reset the index\n",
    "    solarPanels = solarPanels.reset_index(drop=True)\n",
    "\n",
    "    # Drop the subset, pnlsPres columns\n",
    "    solarPanels = solarPanels.drop(columns='pnlsPres')\n",
    "\n",
    "    # Set area\n",
    "    solarPanels['area'] = solarPanels.geometry.area\n",
    "\n",
    "    # Return the geodataframe\n",
    "    return solarPanels\n",
    "\n",
    "# Get the solar panels geodataframe\n",
    "solarPanels = getPanels_method(getPanels_path)\n",
    "\n",
    "# Export the solar panels geodataframes\n",
    "solarPanels.to_file(os.path.join(derivedTemp_path, 'solarPanelsInit.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "# Print the number of panels in each geodataframe and the total area of solar panels\n",
    "print(f'Total number of newly delineated panel-rows: {len(solarPanels)}')\n",
    "print(f'Total area of solar panels on initial processing: {solarPanels.geometry.area.sum() / 1e6:.2f} km2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for High Quality Panels and Create New Array Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove inividual panels by within array design/shape similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stidjaco\\AppData\\Local\\Temp\\ipykernel_31412\\214943546.py:117: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solarArrays.to_file(os.path.join(derivedTemp_path, 'solarArrays_ArrayQAQC.shp'), driver='ESRI Shapefile')\n",
      "C:\\Users\\stidjaco\\AppData\\Local\\Temp\\ipykernel_31412\\214943546.py:118: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solarPanels.to_file(os.path.join(derivedTemp_path, 'solarPanels_PanelQAQC.shp'), driver='ESRI Shapefile')\n",
      "C:\\Users\\stidjaco\\AppData\\Local\\Temp\\ipykernel_31412\\214943546.py:121: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solarPanelsDrop.to_file(os.path.join(derivedTemp_path, 'solarPanelsDropped_PanelQAQC.shp'), driver='ESRI Shapefile')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of panels dropped due to quality control within arrays: 35954\n"
     ]
    }
   ],
   "source": [
    "# Call solar panels\n",
    "solarPanels = gpd.read_file(os.path.join(derivedTemp_path, 'solarPanelsInit.shp'))\n",
    "\n",
    "# Get the mount type, azimuth, length ratio, area ratio, short edge, and long edge for each panel\n",
    "solarPanels[['mount', 'azimuth', 'lengthRatio', 'shortEdge', 'longEdge']] = solarPanels.apply(assignMountType, axis=1, result_type='expand')\n",
    "\n",
    "# Make a new arrayID nativeID the nativeID + Source columns\n",
    "#solarPanels['arrayID'] = solarPanels['nativeID'] + '_' + solarPanels['Source']\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create initial solar arrays from solar panels, and remove low quality arrays and panels\n",
    "\n",
    "# First, drop any panel below the minimum panel area, and greater than the max panel area\n",
    "solarPanels = solarPanels[solarPanels.geometry.area > minPanelRowArea]\n",
    "solarPanels = solarPanels[solarPanels.geometry.area < maxPanelRowArea]\n",
    "\n",
    "# Save solarArrays as copy of solarPanels\n",
    "solarPanels = solarPanels.reset_index(drop=True)\n",
    "\n",
    "# Set an initial panelID 1 through n for the entire dataset\n",
    "solarPanels['panelID'] = range(1, len(solarPanels) + 1)\n",
    "\n",
    "# Create solar arrays from solar panels\n",
    "solarArrays = createArrayFromPanels(solarPanels, panelArrayBuff, arrayIDcol)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Determine panel quality based on panel design parameters within arrays\n",
    "\n",
    "# Here, we will remove commissions based on a number of quality control metrics and determining if panels are outliers. We consider 1 universal metric and 5 within array (local) metrics: PmArRatio (universal), PmArRatio (local), lengthRatio, areaRatio, compactness, and mount proportion. \n",
    "# First, we will determine if a panel is universally an outlier with perimeter to area ratio (PmArRatio) using a set threshold, then within arrays using mount technology proportions, PmArRatio, lengthRatio, areaRatio, and compactness (Poslby-Popper ratio). If 2 or more fail, we will remove the panel.\n",
    "# ~~~~~~~~\n",
    "# PmArRatio is well contrained for square to rectangular objects of solar panel-row size (see percentiles of gmseusInitPanels).We will set a universal miminum threshold for PmArRatio across the entire array to remove large area panel objects that are not solar panels. In gmseusInit, 0.19 was the minimum PmArRatio. We will use 0.18 as the minimum threshold for solar panels.\n",
    "# Universally, low compactness can include long skinny panel-rows and high compactness can include-dual axis or square panel-rows. So we will only use this metric to address within-array varaibility.\n",
    "# Within each array, we will also remove panel-objects where the mount type composes less than 10% of the array. \n",
    "\n",
    "# Set failure threshold (max would be 5)\n",
    "failureThreshold = 2\n",
    "\n",
    "# Set an QAQC column as zero, which we will append to for each failed quality control metric. \n",
    "solarPanels['QAQC'] = 0\n",
    "\n",
    "# Calculate the perimeter to area ratio and compacntess for each panel\n",
    "solarPanels['perimeter'] = solarPanels.geometry.length\n",
    "solarPanels['PmArRatio'] = solarPanels['perimeter'] / solarPanels['area']\n",
    "solarPanels['compactness'] = (4 * np.pi * solarPanels['area']) / (solarPanels['perimeter'] ** 2)\n",
    "\n",
    "# Calculate area ratio, the calculate the panel area to bounding box area ratio, not the minimum bounding rectangle\n",
    "solarPanels['bboxArea'] = solarPanels.geometry.bounds.apply(lambda row: (row['maxx'] - row['minx']) * (row['maxy'] - row['miny']), axis=1)\n",
    "solarPanels['areaRatio'] = solarPanels['area'] / solarPanels['bboxArea']\n",
    "solarPanels = solarPanels.drop(columns='bboxArea')\n",
    "\n",
    "# First, universal removal of comissions based on constrained geometries of ground mounted solar panel-rows (PmArRatio). If PmArRatio is less than the minimum threshold, remove the panel.\n",
    "solarPanels = solarPanels[solarPanels['PmArRatio'] >= minPmArRatio]\n",
    "\n",
    "# Second, remove local (within array) comissions based on within-array mount similarity. If the mount type composes less than 10% of the array, add 1 to QAQC column.\n",
    "solarPanels['uniqueMount'] = solarPanels.groupby([arrayIDcol, 'mount'])['mount'].transform('count') / solarPanels.groupby(arrayIDcol)['mount'].transform('count')\n",
    "solarPanels.loc[solarPanels['uniqueMount'] < uniqueMountThreshold, 'QAQC'] += 1\n",
    "solarPanels = solarPanels.drop(columns='uniqueMount')\n",
    "\n",
    "# Third, remove local (within array) comissions based on within-array PmArRatio, lengthRatio, areaRatio, and compactness (Poslby-Popper ratio). If the panel is an outlier in any of these metrics, add 1 to QAQC column.\n",
    "solarPanels['PmArRatioZ'] = (solarPanels['PmArRatio'] - solarPanels.groupby(arrayIDcol)['PmArRatio'].transform('mean')) / solarPanels.groupby(arrayIDcol)['PmArRatio'].transform('std')\n",
    "solarPanels['lengthRatioZ'] = (solarPanels['lengthRatio'] - solarPanels.groupby(arrayIDcol)['lengthRatio'].transform('mean')) / solarPanels.groupby(arrayIDcol)['lengthRatio'].transform('std')\n",
    "solarPanels['areaRatioZ'] = (solarPanels['areaRatio'] - solarPanels.groupby(arrayIDcol)['areaRatio'].transform('mean')) / solarPanels.groupby(arrayIDcol)['areaRatio'].transform('std')\n",
    "solarPanels['compactnessZ'] = (solarPanels['compactness'] - solarPanels.groupby(arrayIDcol)['compactness'].transform('mean')) / solarPanels.groupby(arrayIDcol)['compactness'].transform('std')\n",
    "solarPanels.loc[solarPanels['PmArRatioZ'].abs() > z_threshold, 'QAQC'] += 1\n",
    "solarPanels.loc[solarPanels['lengthRatioZ'].abs() > z_threshold, 'QAQC'] += 1\n",
    "solarPanels.loc[solarPanels['areaRatioZ'].abs() > z_threshold, 'QAQC'] += 1\n",
    "solarPanels.loc[solarPanels['compactnessZ'].abs() > z_threshold, 'QAQC'] += 1\n",
    "\n",
    "# Drop the Z-score columns\n",
    "solarPanels = solarPanels.drop(columns=['PmArRatioZ', 'lengthRatioZ', 'areaRatioZ', 'compactnessZ'])\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Remove low quality arrays and panels\n",
    "\n",
    "# Get solar panels that fail three or more quality control metrics\n",
    "solarPanelsDrop = solarPanels[solarPanels['QAQC'] >= failureThreshold]\n",
    "\n",
    "# Get solar panels that pass quality control metrics\n",
    "solarPanels = solarPanels[solarPanels['QAQC'] < failureThreshold]\n",
    "\n",
    "# If the resulting array has three or fewer panels, add these to solarPanelsDrop and remove them from solarPanels\n",
    "panelCounts = solarPanels.groupby(arrayIDcol).size().reset_index(name='numPanels')\n",
    "solarPanels = solarPanels.merge(panelCounts, on=arrayIDcol, how='left')\n",
    "solarPanels = solarPanels.reset_index(drop=True)\n",
    "\n",
    "# Get the arrays with too few panels\n",
    "solarPanelsTooFew = solarPanels[solarPanels['numPanels'] <= minNumPanelRows]\n",
    "solarPanelsTooFew = solarPanelsTooFew.drop(columns='numPanels')\n",
    "solarPanelsDrop = pd.concat([solarPanelsDrop, solarPanelsTooFew], ignore_index=True)\n",
    "solarPanels = solarPanels[solarPanels['numPanels'] > minNumPanelRows]\n",
    "\n",
    "# Export \n",
    "#solarPanels.to_file(os.path.join(derivedTemp_path, 'solarPanels.shp'), driver='ESRI Shapefile')\n",
    "#solarPanelsDrop.to_file(os.path.join(derivedTemp_path, 'solarPanelsDrop.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Regenerate solar arrays from the filtered solar panels and export\n",
    "\n",
    "# Regenerate solar arrays from the filtered solar panels\n",
    "solarPanels = solarPanels.reset_index(drop=True)\n",
    "solarPanels = solarPanels.drop(columns=['numPanels'])\n",
    "solarArrays = createArrayFromPanels(solarPanels, panelArrayBuff, arrayIDcol)\n",
    "\n",
    "# Set a new arrayID and panelID that is 1 through n for the entire dataset. First drop old columns.\n",
    "solarArrays = solarArrays.reset_index(drop=True)\n",
    "solarPanels = solarPanels.reset_index(drop=True)\n",
    "solarArrays = solarArrays.drop(columns=['panelID'])\n",
    "solarPanels = solarPanels.drop(columns=[arrayIDcol, 'panelID'])\n",
    "solarPanels['panelID'] = range(1, len(solarPanels) + 1)\n",
    "\n",
    "# Get arrayID for each panel from a spatial join. Get only the arrayID column\n",
    "solarPanels = gpd.sjoin(solarPanels, solarArrays[[arrayIDcol, 'geometry']], how='left', predicate='intersects')\n",
    "solarPanels = solarPanels.drop(columns='index_right')\n",
    "\n",
    "# Reset the index\n",
    "solarPanels = solarPanels.reset_index(drop=True)\n",
    "solarArrays = solarArrays.reset_index(drop=True)\n",
    "\n",
    "# Export high quality arrays and panels\n",
    "solarArrays.to_file(os.path.join(derivedTemp_path, 'solarArrays_ArrayQAQC.shp'), driver='ESRI Shapefile')\n",
    "solarPanels.to_file(os.path.join(derivedTemp_path, 'solarPanels_PanelQAQC.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "# Export solar panels that are dropped\n",
    "solarPanelsDrop.to_file(os.path.join(derivedTemp_path, 'solarPanelsDropped_PanelQAQC.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "# Print the number of panels dropped due to quality control within array\n",
    "print(f'Total number of panels dropped due to quality control within arrays: {len(solarPanelsDrop)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove array-wide panels by quality of new array delineation (new area compared to initial area, and perimeter to area ratio)\n",
    "Importantly, we consider subarray shapes as an array, allowing for unique interarray design distinctions. Thus when we compare the new array area and PmArRatio to the initial, we must explode the initial arrays (this logic is already built into our new solar array delination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of panel-rows removed due to array delineation quality control: 48262\n",
      "Total number of solar arrays: 10355\n",
      "Total number of solar panel-rows: 2291032\n",
      "Total area of solar arrays: 867.18 km2\n",
      "Total area of solar panel-rows: 396.60 km2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stidjaco\\AppData\\Local\\Temp\\ipykernel_45380\\1201970328.py:67: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solarArraysLowQuality.to_file(os.path.join(derivedTemp_path, 'solarArraysLowArrayQuality.shp'), driver='ESRI Shapefile')\n"
     ]
    }
   ],
   "source": [
    "# Call solar panels and arrays\n",
    "solarPanels = gpd.read_file(os.path.join(derivedTemp_path, 'solarPanels_PanelQAQC.shp'))\n",
    "solarArrays = gpd.read_file(os.path.join(derivedTemp_path, 'solarArrays_ArrayQAQC.shp'))\n",
    "\n",
    "# Call initial gmseus arrays\n",
    "gmseusArraysInit = gpd.read_file(gmseusArraysInitPath)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ QAQC (Export high quality arrays and panels compared to initial GM-SEUS arrays)\n",
    "\n",
    "# Reset the index, and calculate the area of the solar arrays\n",
    "solarArrays = solarArrays.reset_index()\n",
    "solarArrays['arrayArea'] = solarArrays.geometry.area\n",
    "\n",
    "# Calculate the perimeter to area ratio of array \n",
    "solarArrays['PmArRatio'] = solarArrays.length / solarArrays.area\n",
    "\n",
    "# Calculate array area and PmArRatio for gmseus initial arrays. First, explode initial gmseus arrays to match logic of panel-row generated arrays (dependent on sub-array shapes, allows for unique array designs within an array area).\n",
    "gmseusArraysInit = gmseusArraysInit.explode(index_parts=False)\n",
    "gmseusArraysInit = gmseusArraysInit.reset_index(drop=True)\n",
    "gmseusArraysInit['arrayArea_gmseus'] = gmseusArraysInit.geometry.area\n",
    "gmseusArraysInit['PmArRatio_gmseus'] = gmseusArraysInit.length / gmseusArraysInit.area\n",
    "\n",
    "# Perform a spatial join to get the gmseus array area and PmArRatio\n",
    "solarArrays = gpd.sjoin(solarArrays, gmseusArraysInit[['arrayArea_gmseus', 'PmArRatio_gmseus', 'geometry']], how='left', predicate='intersects')\n",
    "solarArrays = solarArrays.drop(columns='index_right')\n",
    "\n",
    "# Remove new arrays where the new array area is less than 0.25 * gmseus array area and where new array PmArRatio is less than the 99th percentile of gmseus PmArRatio\n",
    "solarArraysHighQuality = solarArrays[(solarArrays['arrayArea'] > newAreaThreshold * solarArrays['arrayArea_gmseus']) & (solarArrays['PmArRatio'] < gmseusArraysInit['PmArRatio_gmseus'].quantile(gmseusPmArRatioThreshold))]\n",
    "solarArraysHighQuality = solarArraysHighQuality.drop(columns=['arrayArea_gmseus', 'PmArRatio_gmseus'])\n",
    "solarArraysHighQuality = solarArraysHighQuality.reset_index(drop=True)\n",
    "\n",
    "# Drop level_0 and index columns if they exist\n",
    "solarArraysHighQuality = solarArraysHighQuality.drop(columns=['level_0', 'index'], errors='ignore')\n",
    "\n",
    "# Reset index, and filter for panels that are in high quality arrays\n",
    "solarPanels = solarPanels.reset_index(drop=True)\n",
    "solarPanelsHighQuality = solarPanels[solarPanels[arrayIDcol].isin(solarArraysHighQuality[arrayIDcol])].reset_index(drop=True)\n",
    "\n",
    "# Export high quality arrays and panels\n",
    "solarArraysHighQuality.to_file(os.path.join(gmseusNaipArraysPath), driver='ESRI Shapefile')\n",
    "solarPanelsHighQuality.to_file(os.path.join(gmseusNaipPanelsPath), driver='ESRI Shapefile')\n",
    "\n",
    "# Print the number of panels removed due to array delineation quality control\n",
    "print(f'Total number of panel-rows removed due to array delineation quality control: {len(solarPanels) - len(solarPanelsHighQuality)}')\n",
    "\n",
    "# Print the final number of arrays and panels\n",
    "print(f'Total number of solar arrays: {len(solarArraysHighQuality)}')\n",
    "print(f'Total number of solar panel-rows: {len(solarPanelsHighQuality)}')\n",
    "\n",
    "# Print the final area in km2 of arrays and panels\n",
    "print(f'Total area of solar arrays: {solarArraysHighQuality.geometry.area.sum() / 1e6:.2f} km2')\n",
    "print(f'Total area of solar panel-rows: {solarPanelsHighQuality.geometry.area.sum() / 1e6:.2f} km2')\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Export low quality arrays and panels to understand the quality of the delineation\n",
    "\n",
    "# Reset all the indices\n",
    "solarArrays = solarArrays.reset_index()\n",
    "solarPanels = solarPanels.reset_index()\n",
    "solarArraysHighQuality = solarArraysHighQuality.reset_index()\n",
    "solarPanelsHighQuality = solarPanelsHighQuality.reset_index()\n",
    "\n",
    "# Export low quality arrays and panels (not in solarArraysQAQC nativeID)\n",
    "solarArraysLowQuality = solarArrays[~solarArrays[arrayIDcol].isin(solarArraysHighQuality[arrayIDcol])]\n",
    "solarPanelsLowQuality = solarPanels[~solarPanels[arrayIDcol].isin(solarArraysHighQuality[arrayIDcol])]\n",
    "\n",
    "# Export low quality arrays and panels\n",
    "solarArraysLowQuality.to_file(os.path.join(derivedTemp_path, 'solarArraysLowArrayQuality.shp'), driver='ESRI Shapefile')\n",
    "solarPanelsLowQuality.to_file(os.path.join(derivedTemp_path, 'solarPanelsLowArrayQuality.shp'), driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge New Panel Shapes with Existing Ones to Create the Highest Quality Panel Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of final panel-rows in GM-SEUS panel-row dataset: 2924238\n",
      "Total number of panels from GM-SEUS: 1853057\n",
      "Total number of panels from Existing Sources\": 1071181\n",
      "Total area of panels in GM-SEUS panel-row dataset is 468.0124977148468 km2\n"
     ]
    }
   ],
   "source": [
    "# This chunk takes 2800+ minutes to run for 3mil naip panels and 1mil existing panels\n",
    "\n",
    "# Call in GM-SEUS initial panels and GM-SEUS NAIP panels\n",
    "gmseusPanelsInit = gpd.read_file(gmseusPanelsInitPath)\n",
    "gmseusNaipPanels = gpd.read_file(gmseusNaipPanelsPath)\n",
    "\n",
    "# Set an empty instYr column for the gmseus NAIP panels\n",
    "gmseusNaipPanels['instYr'] = np.nan\n",
    "\n",
    "# Set desired panel columns prior to merging\n",
    "panelColumnsInit = ['nativeID', 'Source', 'area', 'instYr', 'geometry']\n",
    "\n",
    "# Select desired columns from gmseusPanelsInit and gmseusNaipPanels\n",
    "gmseusPanelsInit = gmseusPanelsInit[panelColumnsInit]\n",
    "gmseusNaipPanels = gmseusNaipPanels[panelColumnsInit]\n",
    "\n",
    "# Select which dataset to give priority to\n",
    "priorityPanels = gmseusPanelsInit.copy()\n",
    "nonPriorityPanels = gmseusNaipPanels.copy()\n",
    "\n",
    "# Save the panel dataset source to each dataset\n",
    "priorityPanels['pnlSource'] = 'existing'\n",
    "nonPriorityPanels['pnlSource'] = 'gmseus'\n",
    "\n",
    "# Buffer priority panels by 10 meters, dissolve, and unbuffer by -10 meters to create array geometries, and remove non-priority panels intersecting with priority panel arrays\n",
    "priorityPanels_dissolved = priorityPanels.copy()\n",
    "priorityPanels_dissolved['dissovleID'] = 1\n",
    "priorityPanels_dissolved = createArrayFromPanels(priorityPanels, panelArrayBuff, 'dissolveID')\n",
    "priorityPanels_dissolved = priorityPanels_dissolved.drop(columns='dissovleID')\n",
    "\n",
    "# Explode the priority panel arrays to allow parallel processing of spatial join\n",
    "priorityPanels_dissolved = priorityPanels_dissolved.explode(index_parts=False)\n",
    "priorityPanels_dissolved = priorityPanels_dissolved.reset_index(drop=True)\n",
    "\n",
    "# Buffer priority panels by 10 meters, dissolve, and unbuffer by -10 meters to create array geometries, and remove non-priority panels intersecting with priority panel arrays\n",
    "#priorityPanels_buffer = priorityPanels.copy()\n",
    "#priorityPanels_buffer['geometry'] = priorityPanels_buffer.buffer(panelArrayBuff)\n",
    "#priorityPanels_dissolved = priorityPanels_buffer.dissolve()\n",
    "#priorityPanels_dissolved['geometry'] = priorityPanels_dissolved.buffer(-panelArrayBuff)\n",
    "\n",
    "# Remove non-priority panels that intersect with priority panel arrays. Add a tempID column to non-priority panels that is 1 through n\n",
    "nonPriorityPanels['tempID'] = range(1, len(nonPriorityPanels) + 1)\n",
    "intersecting_panels = gpd.sjoin(nonPriorityPanels, priorityPanels_dissolved[['geometry']], how=\"left\", predicate=\"intersects\") # used to be inner, check if this works\n",
    "nonPriorityPanels = nonPriorityPanels[~nonPriorityPanels['tempID'].isin(intersecting_panels['tempID'])]\n",
    "nonPriorityPanels = nonPriorityPanels.drop(columns='tempID')\n",
    "\n",
    "# Merge the panel data\n",
    "mergedPanels = gpd.GeoDataFrame(pd.concat([priorityPanels, nonPriorityPanels], ignore_index=True), crs=gmseusCrs)\n",
    "\n",
    "# Reset the index\n",
    "mergedPanels = mergedPanels.reset_index(drop=True)\n",
    "\n",
    "# Set the final panelID as 1 through n for the entire dataset\n",
    "mergedPanels['panelID'] = range(1, len(mergedPanels) + 1)\n",
    "\n",
    "# If pnlSource is 'gmseus' set Source to 'gmseus'. Else, maintain the Source column\n",
    "mergedPanels.loc[mergedPanels['pnlSource'] == 'gmseus', 'Source'] = 'gmseus'\n",
    "\n",
    "# Drop pnlSource column\n",
    "mergedPanels = mergedPanels.drop(columns='pnlSource')\n",
    "\n",
    "# Print number of rows in mergedPanels\n",
    "print(f'Number of final panel-rows in GM-SEUS panel-row dataset: {len(mergedPanels)}')\n",
    "\n",
    "# Print the total number of panel-rows that have Source as 'gmseus' and that are not 'gmseus\n",
    "print(f'Total number of panels from GM-SEUS: {len(mergedPanels[mergedPanels[\"Source\"] == \"gmseus\"])}')\n",
    "print(f'Total number of panels from Existing Sources: {len(mergedPanels[mergedPanels[\"Source\"] != \"gmseus\"])}')\n",
    "\n",
    "# Print the total sum of 'area' in the mergedPanels dataset in km2\n",
    "print(f'Total area of panels in GM-SEUS panel-row dataset is {mergedPanels[\"area\"].sum() / 1e6} km2')\n",
    "\n",
    "# Export the mergedPanels dataset\n",
    "mergedPanels.to_file(gmseusPanelsFinalPath, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Arrays from Panels for All New an Existing Panel-Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of arrays with panel-row-level information: 12702\n",
      "Total area of GM-SEUS arrays: 1047.29 km2\n"
     ]
    }
   ],
   "source": [
    "# Call in gmseusPanelsFinal\n",
    "gmseusPanelsFinal = gpd.read_file(gmseusPanelsFinalPath)\n",
    "\n",
    "# Call in GM-SEUS initial arrays. Explode the arrays to match the logic of panel-row generated arrays (dependent on sub-array shapes, allows for unique array designs within an array area).\n",
    "gmseusArraysInit = gpd.read_file(gmseusArraysInitPath)\n",
    "gmseusArraysInit = gmseusArraysInit.explode(index_parts=False)\n",
    "gmseusArraysInit = gmseusArraysInit.reset_index(drop=True)\n",
    "\n",
    "# Add a column to gmseusArraysInit that called arrayIDcol (variable set at top of script) and is 1 through n for the entire dataset\n",
    "gmseusArraysInit[arrayIDcol] = range(1, len(gmseusArraysInit) + 1) \n",
    "\n",
    "# Spatially join gmseus arrays to panels, copy the arrayID to the panels, and drop the index columns. \n",
    "gmseusPanelsFinal = gpd.sjoin(gmseusPanelsFinal, gmseusArraysInit[[arrayIDcol, 'geometry']], how='left', predicate='intersects')\n",
    "gmseusPanelsFinal  = gmseusPanelsFinal.reset_index(drop=True)\n",
    "gmseusPanelsFinal  = gmseusPanelsFinal.drop(columns=['index_left', 'index_right'], errors='ignore')\n",
    "gmseusPanelsFinal = gmseusPanelsFinal.dropna(subset=[arrayIDcol]) # Redundent, drop panels that do not have an arrayID, in theory should never be the case\n",
    "\n",
    "# Create arrays from panels -- despite the title, these arrays are generated from new naip panels and existing panels\n",
    "gmseusArraysFromPanels = createArrayFromPanels(gmseusPanelsFinal, panelArrayBuff, arrayIDcol)\n",
    "\n",
    "# Print the number of arrays with panel-row-level infomraiton\n",
    "print(f'Total number of arrays with panel-row-level information: {len(gmseusArraysFromPanels)}')\n",
    "\n",
    "# Print the total area of gmseus arrays final\n",
    "print(f'Total area of GM-SEUS arrays: {gmseusArraysFromPanels.geometry.area.sum() / 1e6:.2f} km2')\n",
    "\n",
    "# Export the GM-SEUS Naip Arrays and gmseusArraysInit with arrayIDcol\n",
    "gmseusArraysFromPanels.to_file(gmseusArraysFromPanelsPath, driver='ESRI Shapefile')\n",
    "gmseusArraysInit.to_file(gmseusArraysInitPath, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge New Arrays with Existing Array Dataset to Create the Highest Quality Array Shapefile\n",
    "* We replace SAM, OSM, and CWSD array boundaries with new array boundaries where detected. These array shapes either do not conform with our array definition, were derived by low spatial resolution methods creating problematic array bounds, or do not have have a standardized delineation methods.\n",
    "* This is what is uploaded to GEE asset and used in script6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of arrays with new boundaries: 6522\n",
      "Total number of arrays in GM-SEUS arrays: 22383\n",
      "Final total area of GM-SEUS arrays: 2947.25 km2\n"
     ]
    }
   ],
   "source": [
    "# Call GMSEUS arrays init and Naip final\n",
    "gmseusArraysInit = gpd.read_file(gmseusArraysInitPath)\n",
    "gmseusArraysFromPanels = gpd.read_file(gmseusArraysFromPanelsPath)\n",
    "\n",
    "# Call in USPVDB and CCVPV original polygons. Here, we call in all spatial array datasets that we are NOT replacing with new NAIP derived arrays.\n",
    "uspvdb = gpd.read_file(uspvdb_path)\n",
    "ccvpv = gpd.read_file(ccvpv_path)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Select when to merge GM-SEUS arrays with existing arrays to create the highest quality array dataset\n",
    "\n",
    "# Add a replaceID column to gmseusArraysFromPanels that is 1\n",
    "gmseusArraysFromPanels['replaceID'] = 1\n",
    "\n",
    "# Set a replaceID column to uspvdb and ccvpv that is 0\n",
    "uspvdb['replaceID'] = 0\n",
    "ccvpv['replaceID'] = 0\n",
    "\n",
    "# In gmseusArraysInit, if Source is SAM, CWSD, or OSM, replace the array geometry with the gmseusArraysFromPanels geometry that intersects that array. If not, retain geometries. Set newBound to 1 if a geometry is replaced.\n",
    "# If source is GMSEUSgeorect, check if array intersects with USPVDB or CCVPV (non-replace geometries identified above). If not, replace the array geometry with the gmseusArraysFromPanels geometry\n",
    "# Additionally, if source is SAM or CWSD, explode the arrays since SAM and CWSD does not necessarily have project level infomration, and merges many array boundaries into one. \n",
    "\n",
    "# Set a new column to gmseusArraysInit that is newBound, which will be a binary indicator for if a new array boundary is used. \n",
    "gmseusArraysInit['newBound'] = 0\n",
    "\n",
    "# ~~~~~~~~~~~~~ Replace SAM, CWSD, and OSM arrays with GMSEUSnaip arrays\n",
    "\n",
    "# Filter for SAM, CWSD, and OSM sources\n",
    "replaceBoundaries = gmseusArraysInit[gmseusArraysInit['Source'].isin(['SAM', 'OSM', 'CWSD'])]\n",
    "\n",
    "# Perform a spatial join to find intersecting geometries from gmseusArraysFromPanels\n",
    "replaceBoundaries_joined = gpd.sjoin(replaceBoundaries, gmseusArraysFromPanels[['geometry', 'replaceID']], how='right', predicate='intersects') # KEY: Take geometry from right side of join\n",
    "\n",
    "# Group by arrayID to get all intersecting geometries, and drop rows where replaceID is null\n",
    "replaceBoundaries_joined = replaceBoundaries_joined.groupby(arrayIDcol).first().reset_index()\n",
    "replaceBoundaries_joined = replaceBoundaries_joined.dropna(subset=['replaceID']).reset_index()\n",
    "\n",
    "# If gmseusArraysInit arrayID is in replaceBoundaries_joined arrayID, set the geometry to the geometry in replaceBoundaries_joined and set newBound to 1\n",
    "gmseusArraysInit = gmseusArraysInit.merge(replaceBoundaries_joined[[arrayIDcol, 'geometry']], on=arrayIDcol, how='left')\n",
    "gmseusArraysInit['geometry'] = np.where(gmseusArraysInit['geometry_y'].isnull(), gmseusArraysInit['geometry_x'], gmseusArraysInit['geometry_y'])\n",
    "gmseusArraysInit['newBound'] = np.where(gmseusArraysInit['geometry_y'].isnull(), gmseusArraysInit['newBound'], 1)\n",
    "gmseusArraysInit = gmseusArraysInit.drop(columns=['geometry_x', 'geometry_y'])\n",
    "\n",
    "# Save as geodataframe\n",
    "gmseusArraysInit = gpd.GeoDataFrame(gmseusArraysInit, crs=gmseusCrs)\n",
    "\n",
    "# # Export gmseusArraysInit\n",
    "# gmseusArraysInit.to_file(os.path.join(derivedTemp_path, 'gmseusArraysInitTESTSPOT1.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "## OLD APPROACH\n",
    "# # Filter for SAM, CWSD, and OSM sources\n",
    "# replaceBoundaries = gmseusArraysInit[gmseusArraysInit['Source'].isin(['SAM', 'OSM', 'CWSD'])]\n",
    "# # Perform a spatial join to find intersecting geometries from gmseusArraysFromPanels\n",
    "# replaceBoundaries_joined = gpd.sjoin(replaceBoundaries, gmseusArraysFromPanels[['geometry']], how='left', predicate='intersects')\n",
    "# # Merge the joined data to bring in the intersecting geometries as a new column\n",
    "# replaceBoundaries_merged = replaceBoundaries_joined.merge(gmseusArraysFromPanels[['geometry']], left_on='index_right', right_index=True, suffixes=('', '_new'))\n",
    "# # Replace the geometry in the original dataframe and set newBound to 1\n",
    "# gmseusArraysInit.loc[replaceBoundaries_merged.index, 'geometry'] = replaceBoundaries_merged['geometry_new']\n",
    "# gmseusArraysInit.loc[replaceBoundaries_merged.index, 'newBound'] = 1\n",
    "# # Export gmseusArraysInit\n",
    "# gmseusArraysInit.to_file(os.path.join(derivedTemp_path, 'gmseusArraysInitTESTSPOT1.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "# ~~~~~~~~~~~~~ Replace GMSEUSgeorect arrays with GMSEUSnaip arrays if they do not intersect with USPVDB or CCVPV\n",
    "\n",
    "# Filter for GMSEUSgeorect source, and then USPVDB, and CCVPV sources\n",
    "gmseusGeorect = gmseusArraysInit[gmseusArraysInit['Source'] == 'GMSEUSgeorect']\n",
    "\n",
    "# Perform spatial joins to identify intersecting rows\n",
    "intersect_uspvdb = gpd.sjoin(gmseusGeorect, uspvdb, how='left', predicate='intersects')\n",
    "intersect_ccvpv = gpd.sjoin(gmseusGeorect, ccvpv, how='left', predicate='intersects')\n",
    "\n",
    "# Drop drop nulls and duplicates\n",
    "intersect_uspvdb = intersect_uspvdb.dropna(subset=['replaceID'])\n",
    "intersect_ccvpv = intersect_ccvpv.dropna(subset=['replaceID'])\n",
    "intersect_uspvdb = intersect_uspvdb.drop_duplicates(subset=arrayIDcol)\n",
    "intersect_ccvpv = intersect_ccvpv.drop_duplicates(subset=arrayIDcol)\n",
    "\n",
    "# Filter gmseusGeorect for arrays that do not intersect with USPVDB or CCVPV\n",
    "gmseusGeorect = gmseusGeorect[~gmseusGeorect[arrayIDcol].isin(intersect_uspvdb[arrayIDcol])]\n",
    "gmseusGeorect = gmseusGeorect[~gmseusGeorect[arrayIDcol].isin(intersect_ccvpv[arrayIDcol])]\n",
    "\n",
    "# Perform a spatial join to find intersecting geometries from gmseusArraysFromPanels\n",
    "gmseusGeorect_joined = gpd.sjoin(gmseusGeorect, gmseusArraysFromPanels[['geometry', 'replaceID']], how='right', predicate='intersects') # KEY: Take geometry from right side of join\n",
    "\n",
    "# Group by arrayID to get all intersecting geometries, and drop rows where replaceID is null\n",
    "gmseusGeorect_joined = gmseusGeorect_joined.groupby(arrayIDcol).first().reset_index()\n",
    "gmseusGeorect_joined = gmseusGeorect_joined.dropna(subset=['replaceID']).reset_index()\n",
    "\n",
    "# If gmseusArraysInit arrayID is in gmseusGeorect_joined arrayID, set the geometry to the geometry in gmseusGeorect_joined and set newBound to 1\n",
    "gmseusArraysInit = gmseusArraysInit.merge(gmseusGeorect_joined[[arrayIDcol, 'geometry']], on=arrayIDcol, how='left')\n",
    "gmseusArraysInit['geometry'] = np.where(gmseusArraysInit['geometry_y'].isnull(), gmseusArraysInit['geometry_x'], gmseusArraysInit['geometry_y'])\n",
    "gmseusArraysInit['newBound'] = np.where(gmseusArraysInit['geometry_y'].isnull(), gmseusArraysInit['newBound'], 1)\n",
    "gmseusArraysInit = gmseusArraysInit.drop(columns=['geometry_x', 'geometry_y'])\n",
    "\n",
    "# Save as geodataframe\n",
    "gmseusArraysInit = gpd.GeoDataFrame(gmseusArraysInit, crs=gmseusCrs)\n",
    "\n",
    "# Export gmseusArraysInit\n",
    "# gmseusArraysInit.to_file(os.path.join(derivedTemp_path, 'gmseusArraysInitTESTSPOT2.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "## OLD APPROACH\n",
    "# # Filter for GMSEUSgeorect source, and then USPVDB, and CCVPV sources\n",
    "# gmseus_georect = gmseusArraysInit[gmseusArraysInit['Source'] == 'GMSEUSgeorect']\n",
    "# # Perform spatial joins to identify intersecting rows\n",
    "# intersect_uspvdb = gpd.sjoin(gmseus_georect, uspvdb, how='left', predicate='intersects')\n",
    "# intersect_ccvpv = gpd.sjoin(gmseus_georect, ccvpv, how='left', predicate='intersects')\n",
    "# # Combine the indices of intersecting rows\n",
    "# intersecting_indices = intersect_uspvdb.index.union(intersect_ccvpv.index)\n",
    "# # Filter out intersecting rows from gmseus_georect\n",
    "# gmseus_georect = gmseus_georect.drop(intersecting_indices)\n",
    "# # Perform a spatial join to find intersecting geometries from gmseusArraysFromPanels\n",
    "# gmseus_georect_joined = gpd.sjoin(gmseus_georect, gmseusArraysFromPanels[['geometry']], how='left', predicate='intersects')\n",
    "# # Merge the joined data to bring in the intersecting geometries as a new column\n",
    "# gmseus_georect_merged = gmseus_georect_joined.merge(gmseusArraysFromPanels[['geometry']], left_on='index_right', right_index=True, suffixes=('', '_new'))\n",
    "# # Replace the geometry in the original dataframe and set newBound to 1\n",
    "# gmseusArraysInit.loc[gmseus_georect_merged.index, 'geometry'] = gmseus_georect_merged['geometry_new']\n",
    "# gmseusArraysInit.loc[gmseus_georect_merged.index, 'newBound'] = 1\n",
    "\n",
    "# ~~~~~~~~~~~~~ For SAM arrays, explode the arrays to get individual array boundaries because SAM does not contain project level information\n",
    "\n",
    "# We do this because SAM has a tendency to identify multiple arrays as one array. Qualitative, this is only the case for SAM, while CWSD tends to underrepsent array area for newly generated bounds and OSM is hand delineated meaning arrays are distinct.\n",
    "\n",
    "# Filter for SAM sources\n",
    "sam = gmseusArraysInit[gmseusArraysInit['Source'] == 'SAM']\n",
    "\n",
    "# Explode the arrays\n",
    "sam_exploded = sam.explode(index_parts=False)\n",
    "\n",
    "# Drop SAM arrays from gmseusArraysInit\n",
    "gmseusArraysInit = gmseusArraysInit[gmseusArraysInit['Source'] != 'SAM']\n",
    "\n",
    "# Concatenate the exploded SAM arrays with gmseusArraysInit\n",
    "gmseusArraysInit = pd.concat([gmseusArraysInit, sam_exploded], ignore_index=True)\n",
    "\n",
    "# # Export gmseusArraysInit\n",
    "# gmseusArraysInit.to_file(os.path.join(derivedTemp_path, 'gmseusArraysInitTESTSPOT3.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "# ~~~~~~~~~~~~~ Save and export the final GM-SEUS arrays and print some statistics\n",
    "\n",
    "# Save copy of gmseusArraysInit as gmseusArraysFinal\n",
    "gmseusArraysFinal = gmseusArraysInit.copy()\n",
    "\n",
    "# Drop roofProp, initID, id, and Subset columns\n",
    "gmseusArraysFinal = gmseusArraysFinal.drop(columns=['roofProp', 'initID', 'id', 'Subset'], errors='ignore')\n",
    "\n",
    "# Add a temporary ID column that is 1 through n for the exploded arrays\n",
    "gmseusArraysFinal['tempID'] = range(1, len(gmseusArraysFinal) + 1)\n",
    "\n",
    "# Count the number of arrays with new boundaries\n",
    "newBoundCount = len(gmseusArraysFinal[gmseusArraysFinal['newBound'] == 1])\n",
    "\n",
    "# Print the number of arrays with new boundaries\n",
    "print(f'Total number of arrays with new boundaries: {newBoundCount}')\n",
    "\n",
    "# Print the total number of arrays in gmseusArraysFinal\n",
    "print(f'Total number of arrays in GM-SEUS arrays: {len(gmseusArraysFinal)}')\n",
    "\n",
    "# Calculate and print the total area of gmseusArraysFinal\n",
    "print(f'Final total area of GM-SEUS arrays: {gmseusArraysFinal.geometry.area.sum() / 1e6:.2f} km2')\n",
    "\n",
    "# Export gmseusArraysFinal\n",
    "gmseusArraysFinal.to_file(gmseusArraysInstYrPath, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLVE issue with initial spatial joining\n",
    "We omitted 537 new array boundaries from the original InstYr analysis due to improper spatial join logic. We've fixed this, but need to re-run LandTrendr for these subarray chunks. Export this followign chunk, and run landtrendr under an \"NewestUpdate\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stidjaco\\AppData\\Local\\Temp\\ipykernel_2424\\2084332435.py:22: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gmseusArraysInstYr.to_file(os.path.join(derivedTemp_path, r'GMSEUS_Arrays_instYr_Update.shp'))\n"
     ]
    }
   ],
   "source": [
    "# Call in gmseusArraysInstYr and the saved version (which has already included the instYr column)\n",
    "gmseusArraysInstYr = gpd.read_file(gmseusArraysInstYrPath)\n",
    "gmseusArraysInstYrCOMPLETE = gpd.read_file(os.path.join(derivedTemp_path, r'GMSEUS_Arrays_instYrSAVE.shp'))\n",
    "\n",
    "# Set completeID to 1\n",
    "gmseusArraysInstYrCOMPLETE['completeID'] = 1\n",
    "\n",
    "# Get gmseusArraysInstYr that do not intersect with COMPLETE using spatial join\n",
    "gmseusArraysInstYr = gpd.sjoin(gmseusArraysInstYr, gmseusArraysInstYrCOMPLETE[['geometry', 'completeID']], how='left', predicate='intersects')\n",
    "\n",
    "# Fill NaN values in completeID with 0\n",
    "gmseusArraysInstYr['completeID'] = gmseusArraysInstYr['completeID'].fillna(0)\n",
    "\n",
    "# Keep only arrays where completeID is 0\n",
    "gmseusArraysInstYr = gmseusArraysInstYr[gmseusArraysInstYr['completeID'] == 0]\n",
    "\n",
    "# Drop completeID column and reset index\n",
    "gmseusArraysInstYr = gmseusArraysInstYr.drop(columns='completeID')\n",
    "gmseusArraysInstYr = gmseusArraysInstYr.reset_index(drop=True)\n",
    "\n",
    "# Export gmseusArraysInstYr\n",
    "gmseusArraysInstYr.to_file(os.path.join(derivedTemp_path, r'GMSEUS_Arrays_instYr_Update.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigPanel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
